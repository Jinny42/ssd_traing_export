<ssd0>
sudo NV_GPU=1 nvidia-docker run --name TFSSD1 -it -d --net=host \
 -v "/drv3/tf_ssd/share:/ssd_ws" \
 tensorflow/tensorflow:1.12.0-gpu-py3

sudo docker exec -it TFSSD1 /bin/bash
sudo docker restart TFSSD1

----------------------------------------------------
2-0 install package

$ pip install lxml
$ pip install pillow
$ pip install Cython
$ apt-get update
$ apt-get install python3-tk
$ pip install --user contextlib2
apt-get install git vim
==========================================================================================================================================================================

2-1 Train용
$ cd /ssd_ws
mkdir tod1
cd tod1

$ git clone https://github.com/tensorflow/models.git
$ mv models train_models

==============
2-3 pycocotools, protocbuf 설치
-----pycocotools 설치-----
$ cd /ssd_ws/tod1/train_models/research

$ export PYTHONPATH=$PYTHONPATH:/ssd_ws/tod1/train_models/research:/ssd_ws/tod1/train_models/research/slim

$ git clone https://github.com/cocodataset/cocoapi.git
$ cd cocoapi/PythonAPI
$ make
$ cp -r pycocotools /ssd_ws/tod1/train_models/research/
-------------------------

-----protocbuf 설치-------
$ cd /ssd_ws/tod1/train_models/research
-
$ curl -OL https://github.com/google/protobuf/releases/download/v3.2.0/protoc-3.2.0-linux-x86_64.zip
$ unzip protoc-3.2.0-linux-x86_64.zip -d protoc3
$ mv protoc3/bin/* /usr/local/bin/
$ mv protoc3/include/* /usr/local/include/
$ protoc object_detection/protos/*.proto --python_out=.
$ python object_detection/builders/model_builder_test.py

OK가 뜨면 성공
----------------------
----------------------

3-3 train model modify
이제 우리가 꾸린 데이터로 train을 할 것이다.
어떤 모델로?: ssd inception v2 
해당 모델로 train을 하기 위해서 tensorflow에서 제공해주는
모델들의 config파일을 통해 쉽게할 수 있다.
해당 config 파일을 우리 데이터를 학습할 수 있도록 수정하자.

$ vim /ssd_ws/tod1/train_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config

**************************************************
line: 151, 152 -> 주석(#) 처리
해당 라인은 transfer learning을 하거나 fine_tuning할 때 사용하므로 현재는 사용하지 않는다.
**************************************************
**만약 transfer 러닝을 하려면 이렇게
  fine_tune_checkpoint: "/ssd_ws/dataset/pretrained/model.ckpt-6919"
  from_detection_checkpoint: true
**************************************************

line: 170,184 -> path설정
해당 라인에 적혀있는 path의 tfrecord를 train하므로 우리데이터셋 경로로 바꿔주자.
170, 184: /ssd_ws/dataset/cocodata/tfrecords/ 여기에 ms만 지우면됨

line: 172,186 -> mscoco_label_map.pbtxt 경로를 설정해줘야 한다. 
172, 186: /ssd_ws/tod1/train_models/research/object_detection/data/mscoco_label_map.pbtxt

3-4 train
이제 학습에 필요한 파라미터들을 설정해주고 실행하면 된다.
mkdir /ssd_ws/tod1/save_models/ 
mkdir /ssd_ws/tod1/save_models/coco_test

$ PIPELINE_CONFIG_PATH='/ssd_ws/tod1/train_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config'
$ MODEL_DIR='/ssd_ws/tod1/save_models/coco_test'

**************************************
$ NUM_TRAIN_STEPS=10000
**************************************************
**만약 transfer 러닝을 하려면
$ NUM_TRAIN_STEPS=5000
******************************************
$ NUM_EVAL_STEPS=100
$ SAMPLE_1_OF_N_EVAL_EXAMPLES=1
------------------------------
터미널을 빠져나가면 안될 듯

$ python object_detection/model_main.py \
--pipeline_config_path=${PIPELINE_CONFIG_PATH} \
--model_dir=${MODEL_DIR} \
--num_train_steps=${NUM_TRAIN_STEPS} \
--num_eval_steps=${NUM_EVAL_STEPS} \
--checkpoint_dir=${PRE_TRAIN} \
--sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
--num_clones=1 \
--ps_tasks=1

==============================================================================================
=================================
<<4 Export pb>>

* MANDATORY !!!! 
exit

$ sudo docker restart TFSSD0
$ sudo docker exec -it TFSSD0 /bin/bash 
===========================================
4-1 Export용 model

$ git clone https://github.com/tensorflow/models.git
$ mv models export_models
$ cd export_models
$ git checkout ae0a9409212d0072938fa60c9f85740bb89ced7e

*다른 브랜치 성공 확인*
.../export_models/research# ls
.../export_models/research# ls ../../train_models/research/
===================

4-2 Export용 model 환경 확인

$ cd /ssd_ws/tod1/export_models/research
$ export PYTHONPATH=$PYTHONPATH:/ssd_ws/tod1/export_models/research:/ssd_ws/tod1/export_models/research/slim

$ protoc object_detection/protos/*.proto --python_out=.
$ python object_detection/builders/model_builder_test.py
--> ok 확인

======================
4-3 Export용 model 설정

cp /ssd_ws/tod1/train_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config ./object_detection/samples/configs/
$ vim ./object_detection/samples/configs/ssd_inception_v2_coco.config
line 101: override 부분 주석

$ INPUT_TYPE=image_tensor

-----------------------------
$ PIPELINE_CONFIG_PATH='/ssd_ws/tod1/export_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config'
ls /ssd_ws/tod1/save_models/coco_test/

**************************************************
$ TRAINED_CKPT_PREFIX='/ssd_ws/tod1/save_models/coco_test/model.ckpt-10000'
**************************************************
**만약 transfer 러닝을 하였다면 이렇게. -> 사실 그냥 가장 큰 숫자의 ckpt 를 사용하면 된다.
**************************************************

mkdir /ssd_ws/tod1/pbfiles

$ EXPORT_DIR='/ssd_ws/tod1/pbfiles'

================================
4-4 Export pb

$ python object_detection/export_inference_graph.py \
--input_type=${INPUT_TYPE} \
--pipeline_config_path=${PIPELINE_CONFIG_PATH} \
--trained_checkpoint_prefix=${TRAINED_CKPT_PREFIX} \
--output_directory=${EXPORT_DIR}

==================================================
